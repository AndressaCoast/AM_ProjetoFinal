<p align="center">

# FunG: Modelagem de distribui√ß√£o de fam√≠lias de Fungos

A proposta do projeto √© elaborar um modelo preditivo com dados sobre esp√©cies de fungos nativos do Brasil para determinar a fam√≠lia predominante de fungos em uma determinada regi√£o. Esse tipo de an√°lise ]pode ser √∫til para fins comerciais, dado que fungos apresentam uma gama de aplica√ß√µes medicinais, culin√°rias, entre outras. Al√©m disso, pode auxiliar em estudos de biogeografia, fornecendo insights sobre como as condi√ß√µes do ambiente culmina na ocorr√™ncia e predomin√¢ncia dessas esp√©cies. 

## Come√ßando

O projeto visa aplicar t√©cnicas de aprendizado de m√°quina para prever a ordem de uma esp√©cie de fungo nativa do Brasil com base em sua localiza√ß√£o. Baseando-se em caracter√≠sticas como municipality, fam√≠lia, longitude m√≠nima e latitude m√≠nima observadas, o modelo busca identificar padr√µes ecol√≥gicos e geogr√°ficos que influenciam a distribui√ß√£o das ordens desses fungos.

As defini√ß√µes de features e target foram feitas da seguinte forma:

*Atributos categ√≥ricos:*<br>

- `municipality`: munic√≠pio que o fungo foi encontrado.

*Atributos num√©ricos:*<br>

- `decimalLatitude`: latitude que o fungo foi encontrado em decimais.
- `decimalLongitude`: longitude que o fungo foi encontrado em decimais.
- `meanElevationInMeters`: m√©dia das colunas originais `minimumElevationInMeters` e `maximumElevationInMeters`, que nos dir√° a altura m√©dia que o fungo pode ser encontrado.

*Target*:
- `family`: fam√≠lia a que o fungo pertence

O conjunto de dados escolhido √© referente √† Cole√ß√£o de Fungos do Herb√°rio SP, que possui cerca de 45 mil de exemplares de fungos pertencentes ao grupo dos basidiomicetos e fungos liquenizados do estado de S√£o Paulo.
No dataset original, havia uma s√©rie de fatores que poderiam atrapalhar a indu√ß√£o de modelos de machine learning, como valores ¬¥NaN¬¥ (Not A Number), classes do target com poucas observa√ß√µes e feature categ√≥rica (municipality). Portanto, foram realizados processos de pr√©-processamento dos dados antes da indu√ß√£o dos modelos de fato.
* Para lidar com os valores `Nan`, foi utilizado o m√©todo `dropna()` do pandas. Ele remove as linhas com esse tipo de informa√ß√£o;
* Quanto √†s classes do target, foi criada uma vari√°vel denominada `logic`, que armazena as classes cuja quantidade de observa√ß√µes √© superior a 100 (Os resultados obtidos podem ser verificados no c√≥digo correspondente). 
* Por fim, foi realizado o processo de encoding (codifica√ß√£o) da feature categ√≥rica com o `One-Hot Encoder`, uma vez que munic√≠pios n√£o s√£o vari√°veis ordinais.

  Ap√≥s essas modifica√ß√µes, os dados tratados s√£o adicionados a um dataset final, que ser√° utilizado nos processos.

## üî® Etapas do projeto

- [ ] Acesso e pr√©-processing de dados.
- [ ] Realizar splitting dos dados e testes.
- [ ] Otimiza√ß√£o com Optuna.
- [ ] Modelo Baseline Classificador.
- [ ] Matriz de confus√£o.
- [ ] Implementar K-NN vizinhos.
- [ ] Implementar floresta aleat√≥ria.
- [ ] Teste com Naive Bayes.
- [ ] Comentar resultados.
      
##  Implanta√ß√£o

Para a implanta√ß√£o desse projeto foi utilizada a interface do Jupyter Notebook para elaborar o c√≥digo fonte, em conjunto com as ferramentas pandas, matplolib, numpy, seaborn, sklearn para carregamento, tratamento e exibi√ß√£o dos dados utilizados no projeto. 

## üõ†Ô∏è Constru√≠do com

As seguintes ferramentas foram utilizadas para a elabora√ß√£o do projeto:

### Estrat√©gia de Holdout:

Tamb√©m conhecida como _train test split_ ou _divis√£o em treino e teste_, tem como fun√ß√£o dividir as vari√°veis utilizadas para a implementa√ß√£o do modelo em unidades de treino e teste, de forma que o modelo tenha features suficientes para ser treinado, mas que ainda tenha dados que desconhece, para ent√£o averiguarmos a acur√°cia do modelo com dados desconhecidos.

### Optuna:

√â um m√≥dulo para resolver problemas envolvendo otimiza√ß√£o com par√¢metros num√©ricos e categ√≥ricos que proprociona buscas mais estrat√©gico do que a busca aleat√≥ria e mais eficiente de que a busca em grade. Pontanto, √© uma estrutura de software de otimiza√ß√£o autom√°tica de hiperpar√¢metros de um modelo de aprendizado de m√°quina que tamb√©m se integra ao  acompanhamento e monitoramento de modelo e avalia√ß√£o.

### Baseline:

Tamb√©m conhecido como Dummy, linha de base ou modelo fict√≠cio. No contexto de ci√™ncia de dados e aprendizado de m√°quina, o baseline pode ser visto como uma solu√ß√£o de refer√™ncia que define um ponto de partida. Ele foi projetado para ser simples e de f√°cil implementa√ß√£o, como um modelo que prev√™ a classe mais frequente (para problemas de classifica√ß√£o).

### Matriz de confus√£o:

√â uma das m√©tricas mais intuitivas e f√°ceis de interpretar para avaliar modelos de classifica√ß√£o. Ela categoriza as previs√µes de um modelo em verdadeiros positivos (VP), falsos positivos(FP), falsos negativos(FN) e verdadeiros negativos(VN).
Obs.: Devido ao target ter quatro classes, ser√° preciso implementar uma matriz de confus√£o para cada classe. 

### K-NN Vizinhos: 

O funcionamento de um modelo preditivo induzido por este algoritmo √© simples: ao receber um certo exemplo x, o algoritmo checa a dist√¢ncia deste exemplo  com rela√ß√£o aos exemplos que ele ja conhece(vizinhos). O valor predito pelo modelo ser√° a m√©dia dos alvos dos k vizinhos mais pr√≥ximos do exemplo de entrada( k vizinhos com menor dist√¢ncia).

### Floresta aleat√≥ria: 

Combina fun√ß√µes de predi√ß√£o aproximadamente n√£o viesadas fazendo uma classifica√ß√£o, treinado com covari√°veis dadas pelas predi√ß√µes dos modelos a serem combinados. √â formada por diversas √°rvores de decis√£o onde o processo de construir cada das √°rvores de decis√£o desta floresta envolve amostragem dos exemplos e de atributos.

### M√©tricas de classifica√ß√£o:

Este m√≥dulo oferece v√°rias fun√ß√µes  para medir o desempenho de modelos de classifica√ß√£o, incluindo fun√ß√µes de perda e pontua√ß√µes. Algumas m√©tricas podem exigir estimativas de probabilidade da classe positiva, valores de confian√ßa ou valores de decis√µes bin√°rias. A maioria das implementa√ß√µes permite que cada amostra forne√ßa uma contribui√ß√£o ponderada √† pontua√ß√£o geral, por meio do par√¢metro. Nesse projeto foi utilizado o m√©todo classification_report que chama as seguintes m√©tricas:

* Recall:
√â uma m√©trica usada para medir a propor√ß√£o de positivos verdadeiros que s√£o corretamente idendtificados. Sendo intuitivamenete a capacidade do classificador de encontrar todas as amostras positivas, √© muito √∫til em situa√ß√µes em que a dete√ß√£o de casos positivos √© crucial e a ocorr√™ncia de falsos negativos √© indejada.
* Acur√°cia:
√â uma m√©trica fundamental que representa a porcentagem de previs√µes corretas feita pelo modelo. √â calculada pela divis√£o do n√∫mero de previs√µes corretas pelo n√∫mero total de previs√µes realizadas pelo modelo. Uma alta acur√°cia indica que o modelo est√° fazendo previs√µes corretas em uma alta porcentagem de casos.
* F1_Score:
√â uma  medida que combina a precision e o recall em uma unica m√©trica, sendo muito essencial para bases de dados desbalanceadas.
* Precision:
√â uma m√©trica que mede a porcentagem de previ√µes corretas em rela√ß√£o ao total de previs√µes. A precis√£o √© calculada dividindo os verdadeiros positivos pelo somat√≥rio dos verdadeiros positivos e dos falsos positivos.

### Naive Bayes (NB):

Os classificadores Naive Bayes s√£o um conjunto de algoritmos probabil√≠sticos que realizam predi√ß√µes com base no Teorema de Bayes. S√£o chamados "naive" (ing√™nuo) porque assumem uma rela√ß√£o de independ√™ncia condicional entre as features que analisa.

$$
P(C | X) = \frac{P(C) P(X | C)}{P(X)}
$$

O Teorema de Bayes descreve a probabilidade de ocorr√™ncia de um evento C ocorrer sabendo que um evento X ocorreu. √â uma ferramenta extremamente poderosa, que proporciona a possibilidade de atualizar uma probabilidade inicial matematicamente, tendo aplica√ß√µes extremamante difundidas em diversas √°reas, como aprendizado de m√°quina, sa√∫de, ou mesmo a vida cotidiana. Para a equa√ß√£o acima, temos os termos:

* $P(C|X):$ probabilidade de C sabendo que X ocorreu.
* $P(X|C):$ probabilidade de X sabendo que C ocorreu.
* $P(C):$ probabilidade inicial de C, o que se sabia de C antes de X ocorrer.
* $P(X):$ √© a probabilidade total de X.

#### Aplica√ß√£o ao contexto

Tomando ainda como refer√™ncia a equa√ß√£o acima, considerando que $X = {X_1, X_2, X_3, ..., X_N}$, sendo X o conjunto das features que contribuem para os dados de treino e teste e que C representa uma classe que estamos tentando prever, o Teorema de Bayes √© aplicado no NB de forma que a cada feature analisada em rela√ß√£o a uma classe tenha probabilidade de ocorrer independente de outra, o que resulta em:

$$
P(X|C) = P(X1|C) * P(X2|C)...P(X_N|C)
$$

Assim, a probabilidade que representa a rela√ß√£o da manisfeta√ß√£o das features dada um determinada classe pode ser representada pelo produto das probabilidades individuais de cada feature. o Teorema de Bayes aplicado ao contexto desse tipo de previs√£o fica:

$$
P(C | X) = \frac{P(X1|C) * P(X2|C)...P(X_N|C)}{P(X)}
$$

Assim, a probabilidade de uma classe C ocorrer se as features $X_1, X_2, ..., X_N$ se manifestarem pode ser calculada pelo teorema. √â importante lembrar que essa probabilidade √© a atualiza√ß√£o de uma probailidade inicial P(C). Como temos 4 classes, esse processo √© realizado para as 4. A classe que possuir a probabilidade mais alta ser√° a indicada como correspondente ao conjunto de features utilizadas no c√°lculo.

Foi mencionado que Naive Bayes √© um conjunto de algoritmos probabil√≠sticos. Como op√ß√µes de algoritmos para implementa√ß√£o dessa l√≥gica, ter√≠amos o `MultinomialNB`, altamente recomendado para a classifica√ß√£o de textos, `BernoulliNB`, recomendado para dados que apresentem distribui√ß√µes Bernoulli multivariadas, `CategoricalNB` para dados distribu√≠dos categoricamente e `GaussianNaiveBayes`, que assume que as vari√°veis analisadas est√£o seguindo uma distribui√ß√£o Gaussiana. 
Os algoritmos que ser√£o implementados nesse projeto ser√£o os de Gaussian Naive Bayes e Complementar Naive Bayes (uma adapta√ß√£o para conjunto de dados desbalanceados). 



## Refer√™ncias

[1]	Optuna - A hyperparameter optimization framework [Internet]. Optuna. Available from: https://optuna.org/.

[2]	CASSAR, Daniel. "ATP-203 3.0 ‚Äì  Modelo linear e baseline.ipynb"  [Material de sala de aula]. Aprendizado de M√°quina, 04 de julho de 2024, Ilum - Escola de Ci√™ncia.

[3] Escola DNC. M√©tricas de Avalia√ß√£o de Modelos de Classifica√ß√£o em Machine Learning - Blog DNC [Internet]. Blog DNC. 2024 [cited 2024 Nov 10]. Available from: https://www.escoladnc.com.br/blog/metricas-de-avaliacao-de-modelos-de-classificacao-em-machine-learning/.

[4] CASSAR, Daniel. "ATP-203 2.1- Aprendizado de m√°quina, k-NN e m√©tricas.ipynb" [Material de sala de aula]. Aprendizado de M√°quina, 07 de agosto de 2024, Ilum - Escola de Ci√™ncia.

[5]	IZBICKI, Rafael; DOS SANTOS, Tiago Mendon√ßa. Aprendizado de m√°quina: uma abordagem estat√≠stica. 2020. Dispon√≠vel em: http://www.rizbicki.ufscar.br/ame/.

[6]	CASSAR, Daniel. "ATP-203 10.0 ‚Äì Outras m√©tricas de classifica√ß√£o.ipynb"  [Material de sala de aula]. Aprendizado de M√°quina, 27 de outubro de 2024, Ilum - Escola de Ci√™ncia.

[7]	Nunes C. O algoritmo Naive Bayes ‚Äî descri√ß√£o e implementa√ß√£o em Python [Internet]. Medium. 2023 [cited 2024 Nov 10]. Available from: https://joaoclaudionc.medium.com/o-algoritmo-naive-bayes-descri%C3%A7%C3%A3o-e-implementa%C3%A7%C3%A3o-em-python-35757ade6b36.

